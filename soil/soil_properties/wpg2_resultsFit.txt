Results of model fitting 'randomForest and XGBoost':


Variable: coarsefrag.vfraction
Ranger result

Call:
 ranger(formula = fm.t, data = dfs, importance = "impurity", write.forest = TRUE,      mtry = t.mrfX$bestTune$mtry, num.trees = 85, case.weights = case.weights.s) 

Type:                             Regression 
Number of trees:                  85 
Sample size:                      687772 
Number of independent variables:  243 
Mtry:                             115 
Target node size:                 5 
Variable importance mode:         impurity 
Splitrule:                        variance 
OOB prediction error (MSE):       70.13744 
R squared (OOB):                  0.7665813 

 Variable importance:
            [,1]
DEPTH 23428703.8
PC2   14023753.9
PC7    4312957.8
PC94   2637899.0
PC4    1817325.2
PC12   1773736.3
PC8    1719417.0
PC241  1680396.6
PC209  1433036.5
PC138  1253677.0
PC64   1103038.6
PC3    1069144.8
PC233  1063865.7
PC165  1042450.4
PC240   986224.9
PC50    952355.5
PC56    951864.7
PC227   945964.8
PC31    938047.1
PC30    921745.4
PC13    912356.0
PC23    897343.1
PC228   894863.3
PC84    886250.8
PC242   885147.5
PC194   872719.3
PC85    870906.3
PC28    856751.9
PC18    843083.1
PC177   827164.0
PC1     817645.4
PC73    784165.0
PC176   776816.8
PC211   772898.0
PC230   768978.4

eXtreme Gradient Boosting 

687772 samples
   243 predictor

No pre-processing
Resampling: Cross-Validated (3 fold, repeated 1 times) 
Summary of sample sizes: 458514, 458514, 458516 
Resampling results across tuning parameters:

  eta  max_depth  nrounds  RMSE      Rsquared   MAE     
  0.3  2           50      15.29508  0.2238664  9.705340
  0.3  2          100      15.04273  0.2494396  9.467322
  0.3  2          150      14.87758  0.2660226  9.327497
  0.3  3           50      14.92530  0.2614607  9.367413
  0.3  3          100      14.55515  0.2986599  9.063615
  0.3  3          150      14.30115  0.3235827  8.873284
  0.3  4           50      14.48863  0.3057093  9.014464
  0.3  4          100      13.98421  0.3546523  8.638748
  0.3  4          150      13.59261  0.3913484  8.356043
  0.4  2           50      15.23494  0.2289226  9.624963
  0.4  2          100      14.95916  0.2567299  9.383691
  0.4  2          150      14.78142  0.2746006  9.243488
  0.4  3           50      14.80974  0.2720285  9.251153
  0.4  3          100      14.43298  0.3093541  8.968064
  0.4  3          150      14.14524  0.3370545  8.756759
  0.4  4           50      14.34750  0.3178858  8.897880
  0.4  4          100      13.80562  0.3695223  8.507905
  0.4  4          150      13.38546  0.4080951  8.213976
  0.5  2           50      15.16883  0.2348827  9.548245
  0.5  2          100      14.89640  0.2624274  9.327134
  0.5  2          150      14.70671  0.2814003  9.186313
  0.5  3           50      14.75631  0.2764177  9.199112
  0.5  3          100      14.31692  0.3194945  8.878642
  0.5  3          150      14.00627  0.3492074  8.663784
  0.5  4           50      14.23724  0.3273904  8.814041
  0.5  4          100      13.63087  0.3840288  8.381445
  0.5  4          150      13.20732  0.4220650  8.085356

Tuning parameter 'gamma' was held constant at a value of 0
Tuning
 parameter 'min_child_weight' was held constant at a value of 1
Tuning
 parameter 'subsample' was held constant at a value of 1
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nrounds = 150, max_depth = 4, eta =
 0.5, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.

 XGBoost variable importance:
    Feature        Gain        Cover   Frequency
 1:     PC2 0.227177445 0.0215129199 0.019132058
 2:   PC233 0.027500634 0.0106187854 0.006532898
 3:     PC7 0.022022320 0.0097481447 0.006066262
 4:    PC12 0.021461292 0.0179814670 0.011199253
 5:   PC165 0.018971003 0.0051733648 0.005132991
 6:   DEPTH 0.017926476 0.0186784037 0.046663556
 7:     PC3 0.016267407 0.0045243778 0.016798880
 8:   PC232 0.015667650 0.0077196569 0.005132991
 9:   PC241 0.014782423 0.0102918274 0.008399440
10:   PC113 0.013327376 0.0061031387 0.003733084
11:   PC227 0.012511020 0.0085672352 0.006999533
12:    PC75 0.011373089 0.0062517156 0.003733084
13:    PC60 0.010129773 0.0019764160 0.005599627
14:    PC84 0.010053190 0.0039513150 0.002799813
15:    PC30 0.009864423 0.0003629826 0.005132991
16:     PC4 0.009600018 0.0072346857 0.012599160
17:    PC31 0.008939804 0.0052973816 0.005599627
18:   PC194 0.008515015 0.0099283092 0.006066262
19:   PC209 0.008291346 0.0055465301 0.005599627
20:    PC47 0.008261895 0.0074631441 0.005599627
21:    PC50 0.008102223 0.0032422861 0.004199720
22:    PC51 0.007264811 0.0064709800 0.004199720
23:    PC18 0.007223171 0.0091639856 0.008399440
24:    PC83 0.007120462 0.0052793499 0.004199720
25:    PC70 0.007059357 0.0041835974 0.004666356
    Feature        Gain        Cover   Frequency


 Support Vector Machine model:
SVM model on 243 features (cookie=1)
 Scenario: LS -1
 Formula:  wpg2 ~ DEPTH + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 +  
    PC9 + PC10 + PC11 + PC12 + PC13 + PC14 + PC15 + PC16 + PC17 +  
    PC18 + PC19 + PC20 + PC21 + PC22 + PC23 + PC24 + PC25 + PC26 +  
    PC27 + PC28 + PC29 + PC30 + PC31 + PC32 + PC33 + PC34 + PC35 +  
    PC36 + PC37 + PC38 + PC39 + PC40 + PC41 + PC42 + PC43 + PC44 +  
    PC45 + PC46 + PC47 + PC48 + PC49 + PC50 + PC51 + PC52 + PC53 +  
    PC54 + PC55 + PC56 + PC57 + PC58 + PC59 + PC60 + PC61 + PC62 +  
    PC63 + PC64 + PC65 + PC66 + PC67 + PC68 + PC69 + PC70 + PC71 +  
    PC72 + PC73 + PC74 + PC75 + PC76 + PC77 + PC78 + PC79 + PC80 +  
    PC81 + PC82 + PC83 + PC84 + PC85 + PC86 + PC87 + PC88 + PC89 +  
    PC90 + PC91 + PC92 + PC93 + PC94 + PC95 + PC96 + PC97 + PC98 +  
    PC99 + PC100 + PC101 + PC102 + PC103 + PC104 + PC105 + PC106 +  
    PC107 + PC108 + PC109 + PC110 + PC111 + PC112 + PC113 + PC114 +  
    PC115 + PC116 + PC117 + PC118 + PC119 + PC120 + PC121 + PC122 +  
    PC123 + PC124 + PC125 + PC126 + PC127 + PC128 + PC129 + PC130 +  
    PC131 + PC132 + PC133 + PC134 + PC135 + PC136 + PC137 + PC138 +  
    PC139 + PC140 + PC141 + PC142 + PC143 + PC144 + PC145 + PC146 +  
    PC147 + PC148 + PC149 + PC150 + PC151 + PC152 + PC153 + PC154 +  
    PC155 + PC156 + PC157 + PC158 + PC159 + PC160 + PC161 + PC162 +  
    PC163 + PC164 + PC165 + PC166 + PC167 + PC168 + PC169 + PC170 +  
    PC171 + PC172 + PC173 + PC174 + PC175 + PC176 + PC177 + PC178 +  
    PC179 + PC180 + PC181 + PC182 + PC183 + PC184 + PC185 + PC186 +  
    PC187 + PC188 + PC189 + PC190 + PC191 + PC192 + PC193 + PC194 +  
    PC195 + PC196 + PC197 + PC198 + PC199 + PC200 + PC201 + PC202 +  
    PC203 + PC204 + PC205 + PC206 + PC207 + PC208 + PC209 + PC210 +  
    PC211 + PC212 + PC213 + PC214 + PC215 + PC216 + PC217 + PC218 +  
    PC219 + PC220 + PC221 + PC222 + PC223 + PC224 + PC225 + PC226 +  
    PC227 + PC228 + PC229 + PC230 + PC231 + PC232 + PC233 + PC234 +  
    PC235 + PC236 + PC237 + PC238 + PC239 + PC240 + PC241 + PC242
  trained and selected on a 13x4780 grid

--------------------------------------
