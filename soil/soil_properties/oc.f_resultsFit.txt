Results of model fitting 'randomForest and XGBoost':


Variable: organic.carbon
Ranger result

Call:
 ranger(formula = fm.t, data = dfs, importance = "impurity", write.forest = TRUE,      mtry = t.mrfX$bestTune$mtry, num.trees = 85, case.weights = case.weights.s) 

Type:                             Regression 
Number of trees:                  85 
Sample size:                      1491844 
Number of independent variables:  243 
Mtry:                             45 
Target node size:                 5 
Variable importance mode:         impurity 
Splitrule:                        variance 
OOB prediction error (MSE):       4.684373 
R squared (OOB):                  0.8342173 

 Variable importance:
           [,1]
DEPTH 3741675.1
PC241 1625899.6
PC234 1015421.2
PC3    798818.7
PC236  636295.4
PC51   480467.0
PC198  435567.6
PC43   434080.0
PC1    382364.9
PC201  368725.1
PC103  325568.3
PC46   321205.8
PC32   310085.5
PC125  292388.8
PC29   279367.4
PC192  275504.6
PC9    269668.0
PC240  261190.5
PC49   256842.6
PC191  245634.3
PC2    240822.6
PC166  238291.4
PC21   237962.3
PC15   229136.1
PC12   225665.6
PC195  215652.3
PC91   213242.2
PC202  203175.7
PC215  198591.3
PC28   198513.7
PC99   197345.3
PC176  196321.7
PC223  193757.9
PC14   192326.3
PC26   191185.6

eXtreme Gradient Boosting 

1491844 samples
    243 predictor

No pre-processing
Resampling: Cross-Validated (3 fold, repeated 1 times) 
Summary of sample sizes: 994563, 994562, 994563 
Resampling results across tuning parameters:

  eta  max_depth  nrounds  RMSE      Rsquared   MAE     
  0.3  2           50      4.295756  0.3504053  1.404799
  0.3  2          100      4.178986  0.3850188  1.375218
  0.3  2          150      4.101540  0.4079490  1.353987
  0.3  3           50      4.075286  0.4167863  1.329598
  0.3  3          100      3.892809  0.4682371  1.277371
  0.3  3          150      3.774396  0.5002598  1.244420
  0.3  4           50      3.834424  0.4846706  1.248418
  0.3  4          100      3.631575  0.5377177  1.191979
  0.3  4          150      3.476227  0.5762735  1.152407
  0.4  2           50      4.270485  0.3566066  1.416384
  0.4  2          100      4.145209  0.3940149  1.381595
  0.4  2          150      4.047608  0.4225074  1.351705
  0.4  3           50      4.026479  0.4289549  1.318386
  0.4  3          100      3.834762  0.4822679  1.265987
  0.4  3          150      3.705057  0.5167002  1.236270
  0.4  4           50      3.772394  0.4996245  1.234362
  0.4  4          100      3.542742  0.5585133  1.179681
  0.4  4          150      3.402352  0.5927449  1.143403
  0.5  2           50      4.243364  0.3639953  1.416479
  0.5  2          100      4.099259  0.4064586  1.371394
  0.5  2          150      3.999101  0.4354509  1.343917
  0.5  3           50      3.958741  0.4471218  1.310329
  0.5  3          100      3.769035  0.4989578  1.257627
  0.5  3          150      3.643494  0.5318054  1.229767
  0.5  4           50      3.726810  0.5101823  1.229424
  0.5  4          100      3.491101  0.5699579  1.174896
  0.5  4          150      3.351053  0.6036464  1.138143

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'colsample_bytree'
 was held constant at a value of 0.8
Tuning parameter 'min_child_weight' was held constant at
 a value of 1
Tuning parameter 'subsample' was held constant at a value of 1
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nrounds = 150, max_depth = 4, eta = 0.5, gamma =
 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.

 XGBoost variable importance:
    Feature        Gain        Cover   Frequency
 1:   PC241 0.203954501 0.0390770848 0.024131274
 2:   DEPTH 0.137681440 0.0580521801 0.113899614
 3:    PC51 0.065933727 0.0074839772 0.005308880
 4:     PC3 0.023617278 0.0599173924 0.036679537
 5:    PC46 0.023116058 0.0014394888 0.002413127
 6:     PC1 0.022649262 0.0134727168 0.040057915
 7:    PC43 0.018503830 0.0288183155 0.015926641
 8:   PC201 0.014874430 0.0177469863 0.011583012
 9:   PC215 0.014658032 0.0093326406 0.005791506
10:   PC186 0.013886405 0.0067310540 0.003861004
11:    PC29 0.011914973 0.0071743944 0.006756757
12:    PC32 0.011195501 0.0179008611 0.009169884
13:    PC96 0.010993188 0.0089817900 0.005791506
14:     PC2 0.008982924 0.0001204049 0.017374517
15:   PC176 0.008914777 0.0112701439 0.005308880
16:    PC28 0.008185905 0.0098373046 0.010135135
17:    PC26 0.007852593 0.0017440242 0.003861004
18:    PC12 0.007669892 0.0002879898 0.006756757
19:   PC223 0.007446257 0.0130002245 0.006756757
20:   PC240 0.007364847 0.0094532064 0.006756757
21:     PC9 0.007320792 0.0109001291 0.010617761
22:   PC210 0.006765149 0.0017850887 0.002895753
23:    PC37 0.006579669 0.0077807549 0.007722008
24:    PC53 0.006508196 0.0048244633 0.005308880
25:   PC196 0.006462796 0.0018136842 0.003378378
    Feature        Gain        Cover   Frequency


 Support Vector Machine model:
SVM model on 243 features (cookie=1)
 Scenario: LS -1
 Formula:  oc.f ~ DEPTH + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 +  
    PC9 + PC10 + PC11 + PC12 + PC13 + PC14 + PC15 + PC16 + PC17 +  
    PC18 + PC19 + PC20 + PC21 + PC22 + PC23 + PC24 + PC25 + PC26 +  
    PC27 + PC28 + PC29 + PC30 + PC31 + PC32 + PC33 + PC34 + PC35 +  
    PC36 + PC37 + PC38 + PC39 + PC40 + PC41 + PC42 + PC43 + PC44 +  
    PC45 + PC46 + PC47 + PC48 + PC49 + PC50 + PC51 + PC52 + PC53 +  
    PC54 + PC55 + PC56 + PC57 + PC58 + PC59 + PC60 + PC61 + PC62 +  
    PC63 + PC64 + PC65 + PC66 + PC67 + PC68 + PC69 + PC70 + PC71 +  
    PC72 + PC73 + PC74 + PC75 + PC76 + PC77 + PC78 + PC79 + PC80 +  
    PC81 + PC82 + PC83 + PC84 + PC85 + PC86 + PC87 + PC88 + PC89 +  
    PC90 + PC91 + PC92 + PC93 + PC94 + PC95 + PC96 + PC97 + PC98 +  
    PC99 + PC100 + PC101 + PC102 + PC103 + PC104 + PC105 + PC106 +  
    PC107 + PC108 + PC109 + PC110 + PC111 + PC112 + PC113 + PC114 +  
    PC115 + PC116 + PC117 + PC118 + PC119 + PC120 + PC121 + PC122 +  
    PC123 + PC124 + PC125 + PC126 + PC127 + PC128 + PC129 + PC130 +  
    PC131 + PC132 + PC133 + PC134 + PC135 + PC136 + PC137 + PC138 +  
    PC139 + PC140 + PC141 + PC142 + PC143 + PC144 + PC145 + PC146 +  
    PC147 + PC148 + PC149 + PC150 + PC151 + PC152 + PC153 + PC154 +  
    PC155 + PC156 + PC157 + PC158 + PC159 + PC160 + PC161 + PC162 +  
    PC163 + PC164 + PC165 + PC166 + PC167 + PC168 + PC169 + PC170 +  
    PC171 + PC172 + PC173 + PC174 + PC175 + PC176 + PC177 + PC178 +  
    PC179 + PC180 + PC181 + PC182 + PC183 + PC184 + PC185 + PC186 +  
    PC187 + PC188 + PC189 + PC190 + PC191 + PC192 + PC193 + PC194 +  
    PC195 + PC196 + PC197 + PC198 + PC199 + PC200 + PC201 + PC202 +  
    PC203 + PC204 + PC205 + PC206 + PC207 + PC208 + PC209 + PC210 +  
    PC211 + PC212 + PC213 + PC214 + PC215 + PC216 + PC217 + PC218 +  
    PC219 + PC220 + PC221 + PC222 + PC223 + PC224 + PC225 + PC226 +  
    PC227 + PC228 + PC229 + PC230 + PC231 + PC232 + PC233 + PC234 +  
    PC235 + PC236 + PC237 + PC238 + PC239 + PC240 + PC241 + PC242
  trained and selected on a 14x8226 grid

--------------------------------------
