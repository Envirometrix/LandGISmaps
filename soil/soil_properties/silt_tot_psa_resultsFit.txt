Results of model fitting 'randomForest and XGBoost':


Variable: silt.wfraction
Ranger result

Call:
 ranger(formula = fm.t, data = dfs, importance = "impurity", write.forest = TRUE,      mtry = t.mrfX$bestTune$mtry, num.trees = 85, case.weights = case.weights.s) 

Type:                             Regression 
Number of trees:                  85 
Sample size:                      1474527 
Number of independent variables:  243 
Mtry:                             115 
Target node size:                 5 
Variable importance mode:         impurity 
Splitrule:                        variance 
OOB prediction error (MSE):       39.53099 
R squared (OOB):                  0.9079935 

 Variable importance:
          [,1]
PC223 58807860
PC241 45240735
DEPTH 38096223
PC4   16224800
PC209 14099467
PC240 13091653
PC235  6982738
PC222  6899556
PC231  6812503
PC234  6705482
PC18   5492582
PC58   4426541
PC227  4387847
PC232  4133885
PC228  4001006
PC62   3932541
PC63   3878960
PC54   3852044
PC68   3764784
PC101  3667923
PC211  3371105
PC16   3318164
PC98   3081492
PC12   3037775
PC3    2988585
PC75   2945459
PC177  2938511
PC15   2858946
PC1    2857568
PC69   2832189
PC41   2648340
PC14   2609795
PC212  2576098
PC178  2539585
PC83   2493011

eXtreme Gradient Boosting 

1474527 samples
    243 predictor

No pre-processing
Resampling: Cross-Validated (3 fold, repeated 1 times) 
Summary of sample sizes: 983018, 983018, 983018 
Resampling results across tuning parameters:

  eta  max_depth  nrounds  RMSE      Rsquared   MAE     
  0.3  2           50      16.16184  0.3940210  12.75945
  0.3  2          100      15.75876  0.4233305  12.38454
  0.3  2          150      15.51678  0.4409433  12.17835
  0.3  3           50      15.54191  0.4394147  12.19382
  0.3  3          100      15.03789  0.4751783  11.74998
  0.3  3          150      14.75034  0.4950433  11.48934
  0.3  4           50      14.96306  0.4805791  11.68569
  0.3  4          100      14.42876  0.5170719  11.20630
  0.3  4          150      14.05770  0.5417628  10.87449
  0.4  2           50      16.06770  0.4000040  12.65015
  0.4  2          100      15.64444  0.4311077  12.27719
  0.4  2          150      15.38539  0.4497988  12.04907
  0.4  3           50      15.38422  0.4499643  12.04077
  0.4  3          100      14.90056  0.4841094  11.61612
  0.4  3          150      14.59691  0.5049520  11.34190
  0.4  4           50      14.82213  0.4895325  11.54891
  0.4  4          100      14.25351  0.5280879  11.03871
  0.4  4          150      13.87856  0.5526311  10.70259
  0.5  2           50      15.97562  0.4063410  12.56927
  0.5  2          100      15.55510  0.4372884  12.20227
  0.5  2          150      15.29806  0.4557207  11.97462
  0.5  3           50      15.31043  0.4547918  11.96523
  0.5  3          100      14.82151  0.4890225  11.52804
  0.5  3          150      14.51457  0.5100239  11.25849
  0.5  4           50      14.76236  0.4930419  11.46680
  0.5  4          100      14.17732  0.5325021  10.95138
  0.5  4          150      13.79619  0.5573551  10.61662

Tuning parameter 'gamma' was held constant at a value of 0
Tuning
 parameter 'min_child_weight' was held constant at a value of 1
Tuning
 parameter 'subsample' was held constant at a value of 1
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nrounds = 150, max_depth = 4, eta =
 0.5, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.

 XGBoost variable importance:
    Feature        Gain       Cover  Frequency
 1:   PC241 0.288591218 0.017680748 0.01398286
 2:   PC223 0.085940470 0.014484529 0.01127650
 3:     PC4 0.062882253 0.023288271 0.01398286
 4:   DEPTH 0.023540936 0.015681338 0.02210194
 5:    PC62 0.020873335 0.010605803 0.00676590
 6:   PC101 0.018819092 0.004438512 0.00225530
 7:   PC227 0.016861638 0.004311585 0.00676590
 8:    PC75 0.016551902 0.002444763 0.00631484
 9:   PC212 0.016513273 0.011994295 0.00766802
10:   PC232 0.015614183 0.007110608 0.00947226
11:   PC231 0.014850878 0.010767970 0.00947226
12:   PC119 0.014184451 0.005001263 0.00405954
13:    PC16 0.012016136 0.004043215 0.00721696
14:   PC240 0.011901940 0.009570644 0.01894452
15:   PC234 0.010380383 0.010429452 0.00766802
16:   PC209 0.009987785 0.006113538 0.00947226
17:    PC63 0.009284392 0.007068371 0.00811908
18:   PC215 0.009167756 0.005142008 0.00541272
19:    PC68 0.009165170 0.010638853 0.00811908
20:   PC237 0.008665642 0.002347375 0.00180424
21:     PC3 0.007642932 0.008844486 0.01037438
22:   PC236 0.006979657 0.006120005 0.00496166
23:    PC86 0.006811458 0.004170729 0.00541272
24:   PC235 0.006169432 0.006811808 0.00451060
25:    PC41 0.005963235 0.006709680 0.00631484
    Feature        Gain       Cover  Frequency


 Support Vector Machine model:
SVM model on 243 features (cookie=1)
 Scenario: LS -1
 Formula:  silt_tot_psa ~ DEPTH + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 +  
    PC8 + PC9 + PC10 + PC11 + PC12 + PC13 + PC14 + PC15 + PC16 +  
    PC17 + PC18 + PC19 + PC20 + PC21 + PC22 + PC23 + PC24 + PC25 +  
    PC26 + PC27 + PC28 + PC29 + PC30 + PC31 + PC32 + PC33 + PC34 +  
    PC35 + PC36 + PC37 + PC38 + PC39 + PC40 + PC41 + PC42 + PC43 +  
    PC44 + PC45 + PC46 + PC47 + PC48 + PC49 + PC50 + PC51 + PC52 +  
    PC53 + PC54 + PC55 + PC56 + PC57 + PC58 + PC59 + PC60 + PC61 +  
    PC62 + PC63 + PC64 + PC65 + PC66 + PC67 + PC68 + PC69 + PC70 +  
    PC71 + PC72 + PC73 + PC74 + PC75 + PC76 + PC77 + PC78 + PC79 +  
    PC80 + PC81 + PC82 + PC83 + PC84 + PC85 + PC86 + PC87 + PC88 +  
    PC89 + PC90 + PC91 + PC92 + PC93 + PC94 + PC95 + PC96 + PC97 +  
    PC98 + PC99 + PC100 + PC101 + PC102 + PC103 + PC104 + PC105 +  
    PC106 + PC107 + PC108 + PC109 + PC110 + PC111 + PC112 + PC113 +  
    PC114 + PC115 + PC116 + PC117 + PC118 + PC119 + PC120 + PC121 +  
    PC122 + PC123 + PC124 + PC125 + PC126 + PC127 + PC128 + PC129 +  
    PC130 + PC131 + PC132 + PC133 + PC134 + PC135 + PC136 + PC137 +  
    PC138 + PC139 + PC140 + PC141 + PC142 + PC143 + PC144 + PC145 +  
    PC146 + PC147 + PC148 + PC149 + PC150 + PC151 + PC152 + PC153 +  
    PC154 + PC155 + PC156 + PC157 + PC158 + PC159 + PC160 + PC161 +  
    PC162 + PC163 + PC164 + PC165 + PC166 + PC167 + PC168 + PC169 +  
    PC170 + PC171 + PC172 + PC173 + PC174 + PC175 + PC176 + PC177 +  
    PC178 + PC179 + PC180 + PC181 + PC182 + PC183 + PC184 + PC185 +  
    PC186 + PC187 + PC188 + PC189 + PC190 + PC191 + PC192 + PC193 +  
    PC194 + PC195 + PC196 + PC197 + PC198 + PC199 + PC200 + PC201 +  
    PC202 + PC203 + PC204 + PC205 + PC206 + PC207 + PC208 + PC209 +  
    PC210 + PC211 + PC212 + PC213 + PC214 + PC215 + PC216 + PC217 +  
    PC218 + PC219 + PC220 + PC221 + PC222 + PC223 + PC224 + PC225 +  
    PC226 + PC227 + PC228 + PC229 + PC230 + PC231 + PC232 + PC233 +  
    PC234 + PC235 + PC236 + PC237 + PC238 + PC239 + PC240 + PC241 +      PC242
  trained and selected on a 14x8541 grid

--------------------------------------
